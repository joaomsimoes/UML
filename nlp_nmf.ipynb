{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import data from S3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['currently sitting at 29',\n '740 dollars so continues to battle',\n 'shorting off of the 21 ema targeting',\n '26 000 and as low down as 19 thousand',\n 'into that 21 ema on a weekly time frame']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.db_conn import query\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# get all the file names from db\n",
    "list_ids = [id[0] for id in query('query_video_ids', ['2022-05-01', '2022-05-30'])]\n",
    "\n",
    "# load the data into a list\n",
    "data = []\n",
    "for id in list_ids:\n",
    "    url = f'https://youtube-joao-crypto.s3.eu-central-1.amazonaws.com/{id}.txt'\n",
    "    response = requests.get(url)\n",
    "    for t in response.text.split('\\n'):\n",
    "        # we only want text or sentences with numbers\n",
    "        if any(map(str.isdigit, t)):\n",
    "            data.append(t)\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the data to txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# with open('utils/prodigy/data.txt', 'w') as f:\n",
    "#     for t in data:\n",
    "#         f.write(t + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use spacy NER module to clean text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\uml\\venv\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.3.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['currently sitting at 29k',\n '740 dollars so continues to battle',\n 'shorting off of the 21 ema targeting',\n '26k k and as low down as 19k thousand',\n 'into that 21 ema on a weekly time frame']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"utils/prodigy/model/model-best\", disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('000', '')\n",
    "    text = text.replace('00', '')\n",
    "    text = text.replace('k', '')\n",
    "    text = text.replace('.', '')\n",
    "\n",
    "    return text\n",
    "\n",
    "final = []\n",
    "for line in data:\n",
    "    doc = nlp(line)\n",
    "    final.append(\" \".join([clean_text(word.text)+'k' if word.ent_type_ else word.text for word in doc]))\n",
    "\n",
    "final[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove stopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = list(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorize data with TFIDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_text = TfidfVectorizer(use_idf=True, min_df=3, max_df=0.8,\n",
    "                             stop_words=stopwords, ngram_range=(1, 2))\n",
    "# Fit and transform to our data\n",
    "# vectors_text is going to be used later in the NMF algorithm\n",
    "vectors_text = tfidf_text.fit_transform(final)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\uml\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 TF-IDF\nsitting        0.657189\ncurrently      0.596867\n29k            0.460274\n00             0.000000\nmajor level    0.000000\n...                 ...\nback december  0.000000\nback 50        0.000000\nback 40k       0.000000\nback 31k       0.000000\nzoom           0.000000\n\n[1841 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TF-IDF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sitting</th>\n      <td>0.657189</td>\n    </tr>\n    <tr>\n      <th>currently</th>\n      <td>0.596867</td>\n    </tr>\n    <tr>\n      <th>29k</th>\n      <td>0.460274</td>\n    </tr>\n    <tr>\n      <th>00</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>major level</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>back december</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>back 50</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>back 40k</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>back 31k</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>zoom</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1841 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pd.DataFrame(vectors_text[0].T.todense(), index=tfidf_text.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "# Sort from the more important to least important\n",
    "tfidf = tfidf.sort_values('TF-IDF', ascending=False)\n",
    "tfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decomposition with NMF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.86460041e-04, 2.74081509e-02, 0.00000000e+00],\n       [2.43577931e-05, 5.48998099e-03, 2.29217430e-04],\n       [5.96036813e-03, 5.93234869e-03, 7.66166755e-05],\n       ...,\n       [0.00000000e+00, 7.20930923e-02, 0.00000000e+00],\n       [0.00000000e+00, 3.56873555e-02, 7.05529466e-04],\n       [0.00000000e+00, 1.89094320e-02, 1.20718259e-03]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_text_model = NMF(n_components=3, random_state=42)\n",
    "w_text_matrix = nmf_text_model.fit_transform(vectors_text)\n",
    "w_text_matrix # rows are documents, columns are topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\uml\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Tópico 1 Tópico 2   Tópico 3\n0       200       50       wave\n1      week      30k      would\n2    moving     2018  wave wave\n3   average  bitcoin       yeah\n4  200 week     back       came",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tópico 1</th>\n      <th>Tópico 2</th>\n      <th>Tópico 3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200</td>\n      <td>50</td>\n      <td>wave</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>week</td>\n      <td>30k</td>\n      <td>would</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>moving</td>\n      <td>2018</td>\n      <td>wave wave</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>average</td>\n      <td>bitcoin</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200 week</td>\n      <td>back</td>\n      <td>came</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = {}\n",
    "new_list = []\n",
    "\n",
    "for topic, word_vector in enumerate(nmf_text_model.components_):\n",
    "    largest = word_vector.argsort()[::-1]\n",
    "    dicts[\"Tópico \" + str(topic+1)] = new_list\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        new_list.append(tfidf_text.get_feature_names()[largest[i]])\n",
    "        if i == 4:\n",
    "            new_list = []\n",
    "\n",
    "df_topicos = pd.DataFrame.from_dict(dicts)\n",
    "df_topicos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}